[![LangGraph](https://img.shields.io/badge/Built_with-LangGraph-00324d.svg)](https://github.com/langchain-ai/langgraph)
[![LangChain](https://img.shields.io/badge/Powered_by-LangChain-1c3c3c.svg)](https://github.com/langchain-ai/langchain)
[![Python](https://img.shields.io/badge/Python-Backend_AI-blue.svg)](https://www.python.org/)

A Local, Voice-Enabled Socratic Conversational Agent

Socrates is a local-first, multilingual conversational agent that engages users using the Socratic method, grounded in Platoâ€™s complete works, enriched with semantic retrieval, and orchestrated through LangGraph.
It can converse via text or voice, running entirely on your own machine using a local Mixtral model.

This project explores how classical philosophy, modern NLP pipelines, and graph-based AI orchestration can meet in a single system.

------------------------------------------------------------------------------------------------------------------------------

âœ¨ Core Features

ğŸ­ Socratic Reasoning
Rather than answering directly, the agent challenges assumptions through reflective questioning.

ğŸ“š Plato as a Knowledge Base
All of Platoâ€™s works are scraped, analyzed, embedded, and stored locally for semantic retrieval.

ğŸ§  Graph-Based Reasoning (LangGraph)
Explicit multi-step reasoning: query generation â†’ retrieval â†’ reflection â†’ response.

ğŸ”Š Voice In / Voice Out
Optional speech-to-text (Whisper) and text-to-speech (Kokoro / Edge / Piper) via a LangGraph sandwich architecture.

ğŸ–¥ï¸ Fully Local LLM
Runs a Spanish fine-tuned Mixtral model locally (GGUF via llama.cpp).

ğŸŒ Multilingual by Design
Optimized for Spanish, but supports cross-lingual retrieval.

--------------------------------------------------------------------------------------------------------------------------------

ğŸ§  Philosophy Meets Pipelines â€” The Data Story

This project does not rely on pre-packaged datasets.

Instead, the knowledge pipeline looks like this:

1. ğŸ•·ï¸ Scraping

Platoâ€™s complete works are scraped from filosofia.org using Scrapy.

2. ğŸ§¬ Linguistic Analysis

Texts are processed with spaCy for NLP analysis and normalization.

3. ğŸ“¦ Structured Storage

The processed output is saved as a structured JSON file: (platon_analisis_nlp.json)

4. ğŸ” Semantic Indexing

Documents are embedded using: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

5. ğŸ§  Socratic Retrieval

Retrieved passages are never answered directly â€” they are used as intellectual tension for Socratic reflection.

-------------------------------------------------------------------------------------------------------------------------------

ğŸ—ï¸ System Architecture

## Retrieval & Reasoning Graph

<p align="center">
  <img src="agent/src/retrieval_graph/assets/Captura%20desde%202026-01-26%2022-50-18.png" width="700"/>
</p>

Flow Overview:

__start__
   â†“
generate_query      â†’ Reformulates the user input into a semantic search query
   â†“
retrieve            â†’ Searches FAISS over Platoâ€™s works
   â†“
reflect_on_question â†’ Applies the Socratic method
   â†“
call_model          â†’ Generates a reflective response (Mixtral)
   â†“
__end__


## Audio Graph (LangGraph Sandwich Architecture)

<p align="center">
  <img src="agent/src/retrieval_graph/assets/Captura%20desde%202026-01-26%2022-50-47.png" width="700"/>
</p>

STT â†’ Socrates (Main Graph) â†’ TTS

This allows the agent to seamlessly accept voice input and return spoken responses, without polluting the reasoning logic.


## Combined Graph View

<p align="center">
  <img src="agent/src/retrieval_graph/assets/Captura%20desde%202026-01-26%2022-51-33.png" width="700"/>
</p>

This view shows how audio processing and reasoning coexist in a single LangGraph system.

-----------------------------------------------------------------------------------------------------------------------------

ğŸš€ Getting Started

git clone https://github.com/pablodeharo/conversational-agent.git
cd conversational-agent/agent
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

âš™ï¸ Configuration
Model Configuration (config/models.yaml)

mixtral:
  backend: llamacpp
  model_path: /path/to/mixtral_spanish_ft.Q4_0.gguf (Your local path) 
  context_length: 8192
  n_gpu_layers: 35
  n_threads: 8
  temperature: 0.7
  top_p: 0.9
  max_tokens: 512

ğŸ“¥ Document Ingestion
python src/retrieval_graph/ingest.py \
  --file data/platon_analisis_nlp.json

  This will:

- Generate embeddings
- Build FAISS index
- Persist everything locally

â–¶ï¸ Running the Agent

langgraph dev --allow-blocking


